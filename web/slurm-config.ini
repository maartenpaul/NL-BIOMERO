[SSH]
# -------------------------------------
# SSH settings
# -------------------------------------
# The alias for the SLURM SSH connection
host = localslurm
# Set the rest of your SSH configuration in your SSH config under this host name/alias
# Or in e.g. /etc/fabric.yml (see Fabric's documentation for details on config loading)

[SLURM]
# -------------------------------------
# Slurm settings
# -------------------------------------
# General settings for where to find things on the Slurm cluster.
# -------------------------------------
# PATHS
# -------------------------------------
# The path on SLURM entrypoint for storing datafiles
#
# Note: 
# This example is NOT relative to the Slurm user's home dir
slurm_data_path = /data/my-scratch/data
# The path on SLURM entrypoint for storing container image files
#
# Note: 
# This example is NOT relative to the Slurm user's home dir
slurm_images_path = /data/my-scratch/singularity_images/workflows
# The path on SLURM entrypoint for storing the slurm job scripts
#
# Note: 
# This example is NOT relative to the Slurm user's home dir
slurm_script_path = /data/my-scratch/slurm-scripts
# -------------------------------------
# REPOSITORIES
# -------------------------------------
# A (github) repository to pull the slurm scripts from.
#
# Note: 
# If you provide no repository, we will generate scripts instead!
# Based on the job_template and the descriptor.json
#
# Example:
# slurm_script_repo=https://github.com/Cellular-Imaging-Amsterdam-UMC/slurm-scripts/
slurm_script_repo = 

# -------------------------------------
# Processing settings
# -------------------------------------
# General/default settings for processing jobs.
# Note: NOT YET IMPLEMENTED
# Note: If you need to change it for a specific case only,
# you should change the job script instead, either in Omero or Slurm 

[ANALYTICS]
# =====================================
# Analytics Settings
# =====================================
# General settings to control workflow tracking 
# and listeners for detailed monitoring and insights.

# -------------------------------------
# WORKFLOW TRACKER SETTINGS
# -------------------------------------
# The workflow tracker collects and logs information 
# on workflow execution, job statuses, and related analytics.
# This is the main switch to enable or disable workflow 
# tracking as a whole.
#
# If disabled, none of the listeners below will be 
# activated, regardless of their individual settings.
#
# Options: True, False
track_workflows = True

# -------------------------------------
# DATABASE CONFIGURATION
# -------------------------------------
# SQLAlchemy database connection URL for persisting 
# workflow analytics data. This setting allows configuring 
# the database connection for storing the tracking and analytics 
# data. If no value is set here, environment variables 
# will be used as the default.
# 
# Example:
# sqlalchemy_url=postgresql+psycopg2://user:password@localhost:5432/yourdatabase
#
# See https://docs.sqlalchemy.org/en/20/core/engines.html#database-urls
# for more info and examples of database URLs supported by sqlalchemy
#
# Note: If SQLALCHEMY_URL is set as an environment variable, 
# it will override this setting.
# sqlalchemy_url=

# -------------------------------------
# LISTENER SETTINGS
# -------------------------------------
# Listeners provide detailed monitoring and insights for 
# specific aspects of workflow execution. Each listener 
# can be enabled or disabled independently.
#
# NOTE: The listeners below will only be active if 
# track_workflows=True.

# -------------------------------------
# JOB ACCOUNTING LISTENER
# -------------------------------------
# Monitors job accounting data such as resource usage 
# (CPU, memory) and SLURM job states (completed, failed).
#
# Options: True, False
enable_job_accounting = True

# -------------------------------------
# JOB PROGRESS LISTENER
# -------------------------------------
# Tracks the progress of SLURM jobs, capturing intermediate 
# statuses for real-time insights into job execution.
#
# Options: True, False
enable_job_progress = True

# -------------------------------------
# WORKFLOW ANALYTICS LISTENER
# -------------------------------------
# Provides detailed insights into workflow performance, 
# including execution times, bottlenecks, and overall 
# efficiency.
#
# Options: True, False
enable_workflow_analytics = True


[CONVERTERS]
# -------------------------------------
# Converters settings
# -------------------------------------
# Settings for linking to external converters.
# 
# By default, BIOMERO exports images as ZARR to the HPC.
# But, the workflow you want to execute might require 
# a different filetype. E.g. most of our example workflows
# require TIFF input files. 
#
# By default we will build a converter on Slurm for you.
# Theoretically you can add other converters here to pull
# those instead. These should be available on dockerhub.
# 
# -------------------------------------
# ZARR TO TIFF
# -------------------------------------
# Uncomment this if you want to pull the image instead of 
# build it. E.g. if you don't have singularity build rights
# on your Slurm.
#
# Please pin it to a specific version to reduce unforeseen errors.
#
# Key should be the types "X_to_Y" and value should be the docker image
# zarr_to_tiff=cellularimagingcf/convert_zarr_to_tiff:1.14.0

[MODELS]
# -------------------------------------
# Model settings
# -------------------------------------
# Settings for models/singularity images that we want to run on Slurm
#
# NOTE: keys have to be unique, and require a <key>_repo and <key>_image value as well.
#
# NOTE 2: Versions for the repo are highly encouraged! 
# Latest/master can change and cause issues with reproducability!
# We pickup the container version based on the version of the repository.
# For generic master branch, we pick up generic latest container.
# 
# -------------------------------------
# Aggregates_measurements
# -------------------------------------
# The path to store the container on the slurm_images_path
aggregates_measurements = aggregates_measurements
# The (e.g. github) repository with the descriptor.json file
aggregates_measurements_repo = https://github.com/Cellular-Imaging-Amsterdam-UMC/W_Measurements-CellProfiler/tree/v1.1.0
# The jobscript in the 'slurm_script_repo'
aggregates_measurements_job = jobs/aggregates_measurements.sh
# 
# -------------------------------------
# Cellexpansion
# -------------------------------------
# The path to store the container on the slurm_images_path
cellexpansion = cellexpansion
# The (e.g. github) repository with the descriptor.json file
cellexpansion_repo = https://github.com/TorecLuik/W_CellExpansion/tree/v2.0.1
# The jobscript in the 'slurm_script_repo'
cellexpansion_job = jobs/cellexpansion.sh
# Adding or overriding job value for this workflow
# 
# -------------------------------------
# Cellpose
# -------------------------------------
# The path to store the container on the slurm_images_path
cellpose = cellpose
# The (e.g. github) repository with the descriptor.json file
cellpose_repo = https://github.com/TorecLuik/W_NucleiSegmentation-Cellpose/tree/v1.3.1
# The jobscript in the 'slurm_script_repo'
cellpose_job = jobs/cellpose.sh
# Adding or overriding job value for this workflow
# Adding or overriding job value for this workflow
cellpose_job_mem = 4GB
# 
# -------------------------------------
# Nuclei_measurements
# -------------------------------------
# The path to store the container on the slurm_images_path
nuclei_measurements = nuclei_measurements
# The (e.g. github) repository with the descriptor.json file
nuclei_measurements_repo = https://github.com/Cellular-Imaging-Amsterdam-UMC/W_Measurements-Nuclei-CellProfiler/tree/v1.0.0
# The jobscript in the 'slurm_script_repo'
nuclei_measurements_job = jobs/nuclei_measurements.sh
# 
# -------------------------------------
# Spotcounting
# -------------------------------------
# The path to store the container on the slurm_images_path
# The (e.g. github) repository with the descriptor.json file
# The jobscript in the 'slurm_script_repo'
# 
# -------------------------------------
# Stardist
# -------------------------------------
# The path to store the container on the slurm_images_path
stardist = stardist
# The (e.g. github) repository with the descriptor.json file
stardist_repo = https://github.com/Neubias-WG5/W_NucleiSegmentation-Stardist/tree/v1.3.2
# The jobscript in the 'slurm_script_repo'
stardist_job = jobs/stardist.sh
[changelog]
# Config automatically updated by root (0) via the web UI on 2025-03-26 15:51:44
