# Brings up all OMERO nodes on _one_ host computer, but multiple containers

# Version 3 is the newest version of the Compose file format
version: "3"

# Define all the services: database, omero server, omero web
services:
  # Name of our database, referenced in omero_db_host
  database:
    # Define a prebuilt Postgres image with a version
    image: "postgres:11"
    # Define environment variables (user/pass here)
    environment:
      POSTGRES_USER: omero
      POSTGRES_DB: omero
      POSTGRES_PASSWORD: omero
    # Define named network to communicate with other containers
    networks:
      - omero
    # Define named volumes to persist data on host after shutdown
    volumes:
      - "database:/var/lib/postgresql/data"

  database-biomero:
    # Define a prebuilt Postgres image with a version
    image: "postgres:16"
    # Define environment variables (user/pass here)
    environment:
      POSTGRES_USER: biomero
      POSTGRES_DB: biomero
      POSTGRES_PASSWORD: biomero
    # Define named network to communicate with other containers
    networks:
      - omero
    # Define named volumes to persist data on host after shutdown
    volumes:
      - "database-biomero:/var/lib/postgresql/data"

  # Name of our omero server, referenced in omero_master_host
  omeroserver:
    # This container uses the tag for the latest server release of OMERO 5
    # To upgrade to the next major release, increment the major version number
    # image: "openmicroscopy/omero-server:5"
    # We build this container locally from the Dockerfile in the ./server folder
    build:
      context: ./
      dockerfile: ./server/Dockerfile
      args:
        BIOMERO_VERSION: ${BIOMERO_VERSION}
    # Define environment variables for use in the container.
    # 'nodedescriptors' assigns roles to all the containers
    # 'omero_db_*' are same as in 'database' description.
    # TODO: Should probably extract those to the .env file
    environment:
      CONFIG_omero_db_host: database
      CONFIG_omero_db_user: omero
      CONFIG_omero_db_pass: omero
      CONFIG_omero_db_name: omero
      CONFIG_omero_scripts_timeout: 604800000
      CONFIG_omero_logging_level: 10
      CONFIG_omero_server_nodedescriptors: >-
        master:Blitz-0
        omeroworker-1:Tables-0,Indexer-0,PixelData-0,DropBox,MonitorServer,FileServer,Storm
        biomeroworker:Processor-0
      CONFIG_omero_master_host: omeroserver
      ROOTPASS: omero
    # Define named network to communicate with other containers
    networks:
      - omero
    # Map ports to ports on the host machine, to connect remotely
    ports:
      - "4063:4063"
      - "4064:4064"
    # Define named volume and map a folder from the host machine
    volumes:
      - "omero:/OMERO"
      - "./web/L-Drive:/data"

  # Name of our worker node, can be anything
  omeroworker-1:
    # We build this image locally in the ./worker folder
    build: ./worker
    # Define variables for use in the container.
    # WORKER_NAME is used in the omero/ice node description
    environment:
      CONFIG_omero_master_host: omeroserver
      OMERO_WORKER_NAME: omeroworker-1
      CONFIG_omero_scripts_timeout: 604800000
    # Named network to communicate with other containers
    networks:
      - omero
    # Named volume to share data access and persist data
    volumes:
      - "omero:/OMERO"
      - "./web/L-Drive:/data"

  # Define our processor worker
  biomeroworker:
    # Build this image locally from current map './'
    # This way we can share file access from Dockerfile in './worker-gpu'
    # Uses args to provide variables from '.env' file to the Dockerfile
    build:
      context: ./
      dockerfile: ./biomeroworker/Dockerfile
      args:
        BIOMERO_VERSION: ${BIOMERO_VERSION}
    # Define variables for use in the container.
    # WORKER_NAME is used in the omero/ice node description
    # logging_level doesn't work, but should increase logging
    environment:
      CONFIG_omero_master_host: omeroserver
      OMERO_WORKER_NAME: biomeroworker
      CONFIG_omero_logging_level: 10
      CONFIG_omero_scripts_timeout: 604800000
      PERSISTENCE_MODULE: eventsourcing_sqlalchemy
      SQLALCHEMY_URL: postgresql+psycopg2://biomero:biomero@database-biomero:5432/biomero
    # Named network to communicate with other containers
    networks:
      - omero
    # Named volume to share data access and persist data
    # Forward host SSH setup to container
    volumes:
      - "omero:/OMERO"
      - "~/.ssh:/tmp/.ssh:ro"
      - "./web/slurm-config.ini:/opt/omero/server/slurm-config.ini:rw"
      - "./web/L-Drive:/data"

  # Service for the omero.web UI
  omeroweb:
    #image: "openmicroscopy/omero-web-standalone:5"
    # We build this also locally in './web' folder, to add some extensions
    # Environment variables for in the container
    build:
      context: ./
      dockerfile: ./web/Dockerfile
      args:
        BIOMERO_VERSION: ${BIOMERO_VERSION}
    environment:
      OMEROHOST: omeroserver
      ROOTPASS: omero
      CONFIG_omero_scripts_timeout: 604800000
      ENV: TEST
      METABASE_SITE_URL: ${METABASE_SITE_URL}
      METABASE_SECRET_KEY: ${METABASE_SECRET_KEY}
      METABASE_IMPORTS_DB_PAGE_DASHBOARD_ID: ${METABASE_IMPORTS_DB_PAGE_DASHBOARD_ID}
      METABASE_WORKFLOWS_DB_PAGE_DASHBOARD_ID: ${METABASE_WORKFLOWS_DB_PAGE_DASHBOARD_ID}
      INGEST_TRACKING_DB_URL: postgresql+psycopg2://biomero:biomero@database-biomero:5432/biomero
      IMPORT_MOUNT_PATH: /data
      FORMS_MASTER_USER: ${FORMS_MASTER_USER}
      FORMS_MASTER_PASSWORD: ${FORMS_MASTER_PASSWORD}
    # Named network to communicate with other containers
    networks:
      - omero
    # Map ports to ports on the host machine, to allow opening of webpage
    ports:
      - "4080:4080"
    # volumes:
    # In case of further development, add volumes for local_omeroweb_edits here
    # Once volumes are added, only omeroweb container reload necessary, not the whole docker-compose.
    volumes:
      - "./web/slurm-config.ini:/opt/omero/web/OMERO.web/var/slurm-config.ini:rw"
      - "./web/L-Drive:/data:rw"
      - "../omero-boost/:/opt/omero/web/omero-boost"
    entrypoint: ["sh", "-c", "tail -f /dev/null"]

  # New Metabase service
  metabase:
    image: metabase/metabase@sha256:f7b5dc52c21aaa2dca910a450e7e6119a975090ce9fc80726aa0742882ca176c
    container_name: metabase
    hostname: metabase
    environment:
      # MB_DB_TYPE: postgres
      # MB_DB_DBNAME: biomero
      # MB_DB_PORT: 5432
      # MB_DB_USER: biomero
      # MB_DB_PASS: biomero
      # MB_DB_HOST: database-biomero
      MB_DB_FILE: /metabase-data/metabase.db
      MB_USER: admin@biomero.com # Admin user email
      MB_PASSWORD: b1omero # Admin user password
    networks:
      - omero
    ports:
      - "3000:3000" # Expose Metabase on port 3000
    volumes:
      - "./metabase:/metabase-data" # Mount existing H2 db

  omeroadi:
    build:
      context: ./omeroadi  # Adjust if needed
      dockerfile: ./Dockerfile  # Path to the Dockerfile for your local build
    privileged: true
    devices:
      - "/dev/fuse:/dev/fuse"
    security_opt:
      - "label=disable"
    environment:
      OMERO_HOST: omeroserver
      OMERO_USER: root
      OMERO_PASSWORD: omero
      OMERO_PORT: 4064
      INGEST_TRACKING_DB_URL: postgresql+psycopg2://biomero:biomero@database-biomero:5432/biomero
    networks:
      - omero
    volumes:
      - "omero:/OMERO"
      - "./web/L-Drive:/data"
      - "./omeroadi/logs:/auto-importer/logs"
      - "./omeroadi/config:/auto-importer/config"
      - "./omeroadi/omero_adi:/auto-importer/omero_adi"
    user: "1000:1000"


# Define the network(s) to communicate between containers
networks:
  omero:

# Define the named volume(s) to persist data to the host computer
volumes:
  database:
  database-biomero:
  omero:
  l-drive:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PWD}/web/L-Drive
